# 第二阶段测试指南 - 用户事件

## 测试目标

验证用户事件的发布和消费功能是否正常工作，包括：
1. 用户服务发布用户生命周期事件
2. 事件服务消费事件并分发给订阅者
3. 订阅者正确接收和处理事件

---

## 前置准备

### 1. 启动基础服务

确保以下服务已启动：
- MySQL（数据库）
- Redis（缓存）
- Kafka（消息队列）
- Nacos（服务注册中心）

### 2. 执行事件定义初始化脚本

```sql
-- 在事件服务的数据库中执行
-- 文件位置：intelli-event-service/src/main/resources/db/init_events.sql

-- 确保包含第二阶段的用户事件定义
SELECT * FROM event_definition WHERE event_code LIKE 'user.%';
```

**预期结果**:
```
+------+----------+-------------+----------------+------------+------------------+--------+
| id   | tenant_id| event_code  | event_name     | event_type | description      | status |
+------+----------+-------------+----------------+------------+------------------+--------+
| xxx  | system   | user.created| 用户创建事件   | USER       | 用户创建时触发   | ACTIVE |
| xxx  | system   | user.updated| 用户更新事件   | USER       | 用户更新时触发   | ACTIVE |
| xxx  | system   | user.deleted| 用户删除事件   | USER       | 用户删除时触发   | ACTIVE |
+------+----------+-------------+----------------+------------+------------------+--------+
```

### 3. 启动服务

按顺序启动以下服务：
1. **事件服务**（intelli-event-service）- 端口 8087
2. **用户服务**（intelli-auth-iam-service）- 端口 8081

### 4. 准备测试工具

- **Postman** 或 **curl**：用于发送 HTTP 请求
- **Kafka 工具**：用于查看 Kafka 消息
- **MySQL 客户端**：用于查询数据库

---

## 测试场景一：用户创建事件

### 测试目标

验证用户创建时是否正确发布 `user.created` 事件。

### 测试步骤

#### 步骤 1: 创建用户

**请求**:
```http
POST http://localhost:8081/v1/users
Content-Type: application/json
Authorization: Bearer {token}

{
  "username": "testuser001",
  "password": "Test@123456",
  "nickname": "测试用户001",
  "email": "testuser001@example.com",
  "phone": "13800138001",
  "roleIds": ["role001", "role002"]
}
```

**预期响应**:
```json
{
  "code": 200,
  "message": "success",
  "data": {
    "id": "user_xxx",
    "username": "testuser001",
    "nickname": "测试用户001",
    "email": "testuser001@example.com",
    "phone": "13800138001",
    "tenantId": "tenant001",
    "roleNames": ["管理员", "开发者"]
  }
}
```

#### 步骤 2: 查看用户服务日志

**预期日志**:
```
[INFO] 发布用户创建事件 - userId: user_xxx, username: testuser001
[DEBUG] 事件发布成功 - eventCode: user.created, tenantId: tenant001
```

**日志位置**: 用户服务控制台或日志文件

#### 步骤 3: 查看 Kafka 消息

使用 Kafka 工具查看 `intellihub-event` Topic 中的消息：

```bash
# 使用 kafka-console-consumer 查看消息
kafka-console-consumer.sh --bootstrap-server 192.168.200.130:9092 \
  --topic intellihub-event \
  --from-beginning \
  --max-messages 1
```

**预期消息格式**:
```json
{
  "tenantId": "tenant001",
  "eventCode": "user.created",
  "source": "auth-iam-service",
  "data": {
    "userId": "user_xxx",
    "username": "testuser001",
    "nickname": "测试用户001",
    "email": "testuser001@example.com",
    "phone": "13800138001",
    "roleIds": ["role001", "role002"],
    "createdAt": "2024-12-31T10:30:00"
  },
  "timestamp": "2024-12-31T10:30:00"
}
```

#### 步骤 4: 查看事件服务日志

**预期日志**:
```
[INFO] 处理事件消息: eventCode=user.created, tenantId=tenant001
[INFO] 查询事件订阅列表: eventCode=user.created, count=x
```

**日志位置**: 事件服务控制台或日志文件

#### 步骤 5: 查看数据库记录

**事件发布记录表**:
```sql
SELECT * FROM event_publish_record 
WHERE event_code = 'user.created' 
ORDER BY created_at DESC 
LIMIT 1;
```

**预期结果**:
```
+------+----------+-------------+--------+------------+---------------------+
| id   | tenant_id| event_code  | status | event_data | created_at          |
+------+----------+-------------+--------+------------+---------------------+
| xxx  | tenant001| user.created| SUCCESS| {...}      | 2024-12-31 10:30:00 |
+------+----------+-------------+--------+------------+---------------------+
```

**事件消费记录表** (如果有订阅者):
```sql
SELECT * FROM event_consume_record 
WHERE event_code = 'user.created' 
ORDER BY consume_time DESC 
LIMIT 1;
```

### 验证检查清单

- [ ] 用户创建成功，返回正确的用户信息
- [ ] 用户服务日志显示事件发布成功
- [ ] Kafka Topic 中有对应的消息
- [ ] 消息格式正确，包含所有必要字段
- [ ] 事件服务日志显示消费成功
- [ ] 事件发布记录已保存到数据库
- [ ] 如果有订阅者，消费记录已保存到数据库

---

## 测试场景二：用户更新事件

### 测试目标

验证用户更新时是否正确发布 `user.updated` 事件。

### 测试步骤

#### 步骤 1: 更新用户信息

**请求**:
```http
PUT http://localhost:8081/v1/users/{userId}
Content-Type: application/json
Authorization: Bearer {token}

{
  "nickname": "测试用户001-已更新",
  "email": "testuser001_new@example.com",
  "phone": "13900139001",
  "avatar": "https://example.com/avatar.jpg"
}
```

**预期响应**:
```json
{
  "code": 200,
  "message": "success",
  "data": {
    "id": "user_xxx",
    "username": "testuser001",
    "nickname": "测试用户001-已更新",
    "email": "testuser001_new@example.com",
    "phone": "13900139001",
    "avatar": "https://example.com/avatar.jpg"
  }
}
```

#### 步骤 2: 查看用户服务日志

**预期日志**:
```
[INFO] 发布用户更新事件 - userId: user_xxx, username: testuser001
[DEBUG] 事件发布成功 - eventCode: user.updated, tenantId: tenant001
```

#### 步骤 3: 查看 Kafka 消息

**预期消息格式**:
```json
{
  "tenantId": "tenant001",
  "eventCode": "user.updated",
  "source": "auth-iam-service",
  "data": {
    "userId": "user_xxx",
    "username": "testuser001",
    "nickname": "测试用户001-已更新",
    "email": "testuser001_new@example.com",
    "phone": "13900139001",
    "updatedAt": "2024-12-31T10:35:00"
  },
  "timestamp": "2024-12-31T10:35:00"
}
```

#### 步骤 4: 查看数据库记录

```sql
SELECT * FROM event_publish_record 
WHERE event_code = 'user.updated' 
ORDER BY created_at DESC 
LIMIT 1;
```

### 验证检查清单

- [ ] 用户更新成功，返回更新后的用户信息
- [ ] 用户服务日志显示事件发布成功
- [ ] Kafka Topic 中有对应的消息
- [ ] 消息包含更新后的用户信息
- [ ] 事件服务日志显示消费成功
- [ ] 事件发布记录已保存到数据库

---

## 测试场景三：用户删除事件

### 测试目标

验证用户删除时是否正确发布 `user.deleted` 事件。

### 测试步骤

#### 步骤 1: 删除用户

**请求**:
```http
DELETE http://localhost:8081/v1/users/{userId}
Authorization: Bearer {token}
```

**预期响应**:
```json
{
  "code": 200,
  "message": "success"
}
```

#### 步骤 2: 验证软删除

```sql
SELECT id, username, deleted_at 
FROM iam_user 
WHERE id = 'user_xxx';
```

**预期结果**:
```
+----------+-------------+---------------------+
| id       | username    | deleted_at          |
+----------+-------------+---------------------+
| user_xxx | testuser001 | 2024-12-31 10:40:00 |
+----------+-------------+---------------------+
```

#### 步骤 3: 查看用户服务日志

**预期日志**:
```
[INFO] 发布用户删除事件 - userId: user_xxx, username: testuser001
[DEBUG] 事件发布成功 - eventCode: user.deleted, tenantId: tenant001
```

#### 步骤 4: 查看 Kafka 消息

**预期消息格式**:
```json
{
  "tenantId": "tenant001",
  "eventCode": "user.deleted",
  "source": "auth-iam-service",
  "data": {
    "userId": "user_xxx",
    "username": "testuser001",
    "deletedAt": "2024-12-31T10:40:00"
  },
  "timestamp": "2024-12-31T10:40:00"
}
```

#### 步骤 5: 查看数据库记录

```sql
SELECT * FROM event_publish_record 
WHERE event_code = 'user.deleted' 
ORDER BY created_at DESC 
LIMIT 1;
```

### 验证检查清单

- [ ] 用户删除成功
- [ ] 数据库中用户记录的 deleted_at 字段已设置
- [ ] 用户服务日志显示事件发布成功
- [ ] Kafka Topic 中有对应的消息
- [ ] 消息包含用户ID和删除时间
- [ ] 事件服务日志显示消费成功
- [ ] 事件发布记录已保存到数据库

---

## 测试场景四：事件消费和分发

### 前置条件

需要先配置事件订阅关系。

#### 步骤 1: 创建订阅

**请求**:
```http
POST http://localhost:8087/v1/event-subscriptions/create
Content-Type: application/json

{
  "tenantId": "tenant001",
  "eventCode": "user.created",
  "subscriberName": "通知服务-欢迎邮件",
  "subscriberType": "WEBHOOK",
  "callbackUrl": "http://localhost:9999/webhook/user-created",
  "callbackMethod": "POST",
  "retryStrategy": "FIXED",
  "maxRetryTimes": 3,
  "priority": 5
}
```

#### 步骤 2: 启动 Webhook 测试服务器

创建一个简单的 HTTP 服务器来接收 Webhook 回调：

```python
# webhook_test_server.py
from flask import Flask, request
import json

app = Flask(__name__)

@app.route('/webhook/user-created', methods=['POST'])
def user_created():
    data = request.json
    print(f"收到用户创建事件: {json.dumps(data, indent=2, ensure_ascii=False)}")
    return {'status': 'success'}

@app.route('/webhook/user-updated', methods=['POST'])
def user_updated():
    data = request.json
    print(f"收到用户更新事件: {json.dumps(data, indent=2, ensure_ascii=False)}")
    return {'status': 'success'}

@app.route('/webhook/user-deleted', methods=['POST'])
def user_deleted():
    data = request.json
    print(f"收到用户删除事件: {json.dumps(data, indent=2, ensure_ascii=False)}")
    return {'status': 'success'}

if __name__ == '__main__':
    app.run(port=9999)
```

运行：
```bash
python webhook_test_server.py
```

#### 步骤 3: 触发事件

创建一个新用户（参考测试场景一）。

#### 步骤 4: 查看 Webhook 服务器日志

**预期输出**:
```
收到用户创建事件: {
  "tenantId": "tenant001",
  "eventCode": "user.created",
  "source": "auth-iam-service",
  "data": {
    "userId": "user_xxx",
    "username": "testuser002",
    "nickname": "测试用户002",
    "email": "testuser002@example.com",
    "phone": "13800138002",
    "roleIds": ["role001"],
    "createdAt": "2024-12-31T11:00:00"
  },
  "timestamp": "2024-12-31T11:00:00"
}
```

#### 步骤 5: 查看事件消费记录

```sql
SELECT * FROM event_consume_record 
WHERE subscription_id = '{订阅ID}' 
ORDER BY consume_time DESC 
LIMIT 1;
```

**预期字段**:
- `status`: `SUCCESS`
- `response_code`: `200`
- `retry_times`: `0`
- `duration_ms`: 消费耗时（毫秒）

### 验证检查清单

- [ ] 订阅创建成功
- [ ] Webhook 服务器正常运行
- [ ] 事件服务成功查询订阅列表
- [ ] 事件服务成功调用 Webhook
- [ ] Webhook 服务器成功接收事件
- [ ] 事件数据完整且格式正确
- [ ] 消费记录已保存到数据库
- [ ] 消费状态为 SUCCESS

---

## 完整测试流程

### 测试准备

1. 启动所有基础服务（MySQL, Redis, Kafka, Nacos）
2. 执行事件定义初始化 SQL 脚本
3. 启动事件服务
4. 启动用户服务
5. 启动 Webhook 测试服务器（可选）

### 测试执行

#### 测试 1: 用户创建事件
1. 创建用户
2. 检查日志
3. 检查 Kafka 消息
4. 检查数据库记录

#### 测试 2: 用户更新事件
1. 更新用户信息
2. 检查日志
3. 检查 Kafka 消息
4. 检查数据库记录

#### 测试 3: 用户删除事件
1. 删除用户
2. 检查软删除
3. 检查日志
4. 检查 Kafka 消息
5. 检查数据库记录

#### 测试 4: 事件消费和分发
1. 创建订阅
2. 触发事件
3. 检查 Webhook 回调
4. 检查消费记录

### 测试验证

- [ ] 所有事件都能正确发布到 Kafka
- [ ] 事件服务能正确消费事件
- [ ] 事件数据格式正确
- [ ] 订阅者能正确接收事件
- [ ] 所有日志记录完整
- [ ] 所有数据库记录正确

---

## 常见问题排查

### 问题 1: 用户服务无法启动

**可能原因**:
- Kafka 依赖未正确编译

**解决方案**:
```bash
cd d:\Develop\Code_github\intelli_hub\intellihub-parent
# 在 IDE 中执行 Maven -> Reimport
# 或者编译 kafka-spring-boot-starter 模块
```

### 问题 2: 事件未发布到 Kafka

**排查步骤**:
1. 检查 Kafka 是否正常运行
2. 检查用户服务日志是否有错误
3. 检查 Kafka 配置是否正确（bootstrap-servers）
4. 检查 UserEventPublisher 是否正确注入

**查看 Kafka Topic**:
```bash
kafka-topics.sh --bootstrap-server 192.168.200.130:9092 --list
```

### 问题 3: 事件服务未消费事件

**排查步骤**:
1. 检查事件服务是否正常启动
2. 检查 EventConsumer 是否有错误日志
3. 检查 Kafka Consumer Group 是否正常

**查看 Consumer Group**:
```bash
kafka-consumer-groups.sh --bootstrap-server 192.168.200.130:9092 \
  --describe --group event-service-group
```

### 问题 4: Webhook 调用失败

**排查步骤**:
1. 检查 Webhook URL 是否可访问
2. 检查订阅配置是否正确
3. 查看事件消费记录表的 `error_message` 字段

**查询失败记录**:
```sql
SELECT * FROM event_consume_record 
WHERE status = 'FAILED' 
ORDER BY consume_time DESC 
LIMIT 10;
```

### 问题 5: 事件数据不完整

**排查步骤**:
1. 检查 UserServiceImpl 中的事件发布代码
2. 检查传递给 publishUserXxx 方法的参数
3. 查看 Kafka 消息的原始内容

---

## 性能测试

### 测试目标

验证用户事件发布的性能和稳定性。

### 测试方案

#### 1. 并发创建用户测试

使用 JMeter 或其他压测工具：
- 并发数：50
- 持续时间：5 分钟
- 预期 TPS：500+

#### 2. 消费延迟测试

监控事件从发布到消费的延迟：
- 预期延迟：< 1 秒（P95）
- 预期延迟：< 2 秒（P99）

#### 3. 消息堆积测试

停止事件服务，持续创建用户，观察 Kafka 消息堆积：
- 预期：消息正常堆积，不丢失
- 重启事件服务后，消息正常消费

### 监控指标

**Kafka 指标**:
- Topic 消息数量
- Consumer Lag（消费延迟）
- 分区分布

**数据库指标**:
- 事件发布记录数
- 事件消费记录数
- 失败记录数

**应用指标**:
- 事件发布成功率
- 事件消费成功率
- 平均消费耗时

---

## 测试报告模板

### 测试环境

- 测试时间：2024-12-31
- 测试人员：XXX
- 环境：开发环境 / 测试环境

### 测试结果

| 测试场景 | 测试结果 | 备注 |
|---------|---------|------|
| 用户创建事件 | ✅ 通过 | 所有检查项通过 |
| 用户更新事件 | ✅ 通过 | 所有检查项通过 |
| 用户删除事件 | ✅ 通过 | 所有检查项通过 |
| 事件消费和分发 | ✅ 通过 | Webhook 回调成功 |

### 发现的问题

| 问题描述 | 严重程度 | 状态 | 解决方案 |
|---------|---------|------|---------|
| 无 | - | - | - |

### 测试结论

- [ ] 所有测试场景通过
- [ ] 事件发布功能正常
- [ ] 事件消费功能正常
- [ ] 可以进入下一阶段开发

---

## 参考文档

- [第二阶段开发说明](./33-事件中心-第二阶段开发说明.md)
- [事件中心实施计划](./30-事件中心-实施计划.md)
- [第一阶段测试指南](./32-事件中心-第一阶段测试指南.md)
